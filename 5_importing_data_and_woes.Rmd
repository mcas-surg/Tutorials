---
title: 'Data importation woes'
author: "Matthew Castelo"
date: "June, 2021"
output:
  pdf_document:
    fig_caption: yes
  html_document:
    df_print: paged
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
library(formatR)
library(knitr)
knitr::opts_chunk$set(tidy = FALSE, 
                      message = FALSE, warning = FALSE,
                      out.width = "75%", fig.align = 'center')
```

This is an introduction to importing datasets into R, and some immediate problems that often present themselves. We will cover importing .csv files, Excel spreadsheets, and SAS datasets. In terms of data cleaning, we will also address quickly fixing non-standard variable names, fixing missing data indicators, and changing variable types (i.e. character to numeric).

We will need to install the following packages. 

```{r, eval = FALSE}
install.packages("tidyverse")
```

As usual, we will load our packages and set the working directory. 

```{r}
library(tidyverse)
library(readxl) #This allows importing of Excel files
library(haven) #This allows importing of SAS files

#The working directory saves the following path when loading files, saving plots, etc
setwd("C:/Users/matth/Documents/R/R code and education/Tutorials/")
```

# Importing .csv files

A .csv, or comma separated value file is a common format for datasets. Each line is an observation and values (columns) are separated by a comma. These files will often open in your standard spreadsheet software (i.e. Excel) and it might not be apparent at first they are different file types. CSV files do not have sheets like Excel files, and do not support formulae. 

First, some history. For a long time, the base R function `read.csv()` had a very problematic default behaviour. Any variable that contained text would be automatically imported as a factor. Factors are categorical variables that have an explicitly defined order, or levels, to them. They allow you to convert a numeric variable like year of diagnosis to a categorical variable. It can also be useful to convert character variables to factors to control the order of output in legends, etc. However, routinely converting character strings to factors during data importation caused unexpected errors and made it difficult to reproduce analyses. Therefore, it was standard to include the argument `stringAsFactors = FALSE` when using `read.csv()`. 

This annoying problem was addressed with the **Tidyverse** alternative, `read_csv()`, which by default imports strings as character variables. Note the underscore instead of the period. This function also conveniently prints the type of each variable after they've been imported. These days, even the default of `read.csv()` has been changed but I still prefer `read_csv()` as it meshes better with the rest of **Tidyverse**. 

Our first dataset is on GitHub, so let's import it using this function. 

```{r}
urlRemote  <- "https://raw.githubusercontent.com/"
pathGithub <- "mcas-surg/Tutorials/main/Datasets/"
fileName   <- "generic_cancer.csv"

cancer <- read_csv(paste0(urlRemote, pathGithub, fileName))
```

Normally you will be importing files from your computer. The following format will make more sense. 

```{r, eval=FALSE}
cancer <- read_csv(
  "C:/Users/matth/Documents/R/R code and education/Tutorials/Datasets/generic_cancer.csv")

#As I have already set my working directory up to /Tutorials/ in this path, 
#I can omit most of this pathway. The following is equivalent

cancer <- read_csv("Datasets/generic_cancer.csv")
```

You should see the type of each column print in the console. Let's take a closer look using `glimpse()` and `head()`. 

```{r}
glimpse(cancer)

head(cancer)
```

To get a spreadsheet-type view, we can use.

```{r, eval = FALSE}
View(cancer)
```


We can see the variables *pt_id*, *age*, *tumour_size*, and *follow_up* were imported as `<dbl>`, which is a type of numeric variable. Everything else was imported as a character.

The variable names also look good. R has some rules for variable names. They must start with a letter and can contain letters, numbers, periods, and underscores. R is case-sensitive. If the variable is called *Height*, trying to print `dataset$height` will not work. Variable names cannot have spaces in them.

This is an ideal case, where the dataset was provided as a .csv file and all the variable names are compatible. We will explore how to do some initial cleaning later in the tutorial. 

# Importing .txt files and other delimeters 

Sometimes, a dataset will be CSV, i.e. values separated by commas, but they will not be in a .csv format. They will simply be pasted in a text file. 

```{r, echo=FALSE, out.width="100%"}
knitr::include_graphics("C:/Users/matth/Documents/R/R code and education/Tutorials/Photos/csv_as_text.png")
```

This is treated the same as before using `read_csv()`, just make sure we indicate the correct file type as `file_name.txt`. 

```{r}
urlRemote  <- "https://raw.githubusercontent.com/"
pathGithub <- "mcas-surg/Tutorials/main/Datasets/"
fileName   <- "txt_csv_example.txt" #Here you can see the file name ends in .txt now

csv_as_text <- read_csv(paste0(urlRemote, pathGithub, fileName))

head(csv_as_text)
```

Remember we are working from GitHub so you can download the files. On your computer this would look something like. 

```{r, eval=FALSE}
csv_as_text <- read_csv("Datasets/txt_csv_example.txt")
```

By default the first line will be treated as the column names. If they are not included, we must tell R to ignore the first line and we can manually provide the column names afterwards.

```{r, echo=FALSE, out.width="100%"}
knitr::include_graphics("C:/Users/matth/Documents/R/R code and education/Tutorials/Photos/csv_as_text_no_names.png")
```

If we import as normal. 

```{r}
urlRemote  <- "https://raw.githubusercontent.com/"
pathGithub <- "mcas-surg/Tutorials/main/Datasets/"
fileName   <- "txt_csv_no_names.txt"

csv_no_names <- read_csv(paste0(urlRemote, pathGithub, fileName))

head(csv_no_names)
```

The first line of data was imported as the column names. Let's set `col_names = FALSE`.

```{r}
urlRemote  <- "https://raw.githubusercontent.com/"
pathGithub <- "mcas-surg/Tutorials/main/Datasets/"
fileName   <- "txt_csv_no_names.txt"

csv_no_names <- read_csv(paste0(urlRemote, pathGithub, fileName),
                         col_names = FALSE)

head(csv_no_names)
```

R automatically filled in the variables names with *X1*, *X2*, etc. We can name them whatever we want using the `colnames()` function. Normally, this prints out a vector of the column names.

```{r}
colnames(csv_no_names)
```

If we pass a different vector to this they will be updated. 

```{r}
colnames(csv_no_names) <- c("hospital",
                            "age",
                            "surgery")

head(csv_no_names)
```

Many of these .txt files will have a paragraph preceding the data giving some information about the dataset. This can be a problem during importation. 

```{r, echo=FALSE, out.width="100%"}
knitr::include_graphics("C:/Users/matth/Documents/R/R code and education/Tutorials/Photos/csv_as_text_preamble.png")
```

We can see there are 7 lines of nonsense. Let's skip these lines using the argument `skip = 7`. 

```{r}
urlRemote  <- "https://raw.githubusercontent.com/"
pathGithub <- "mcas-surg/Tutorials/main/Datasets/"
fileName   <- "txt_csv_preamble.txt"

csv_preamble <- read_csv(paste0(urlRemote, pathGithub, fileName),
                         skip = 7)

head(csv_preamble)
```

A CSV file is really one type of a larger group of data formats, called delimited files. A delimiter is a character that separates values. The delimiter in CSV files are, unsurprisingly, commas. You can have other delimiters such as periods, tabs, or backslashes. They can be read using the more flexible function `read_delim()` and telling R the specific delimiter. 

Let's read in a period delimited and tab delimited file. 

```{r, echo=FALSE, out.width="100%"}
knitr::include_graphics("C:/Users/matth/Documents/R/R code and education/Tutorials/Photos/period_delim.png")
```

```{r}
urlRemote  <- "https://raw.githubusercontent.com/"
pathGithub <- "mcas-surg/Tutorials/main/Datasets/"
fileName   <- "period_delim.txt"

period_delim <- read_delim(paste0(urlRemote, pathGithub, fileName),
                         delim = ".")
```

```{r, echo=FALSE, out.width="100%"}
knitr::include_graphics("C:/Users/matth/Documents/R/R code and education/Tutorials/Photos/tab_delim.png")
```

```{r}
urlRemote  <- "https://raw.githubusercontent.com/"
pathGithub <- "mcas-surg/Tutorials/main/Datasets/"
fileName   <- "tab_delim.txt"

tab_delim <- read_delim(paste0(urlRemote, pathGithub, fileName),
                        delim = "\t")
```

# Importing Excel files

Excel files have characteristics that can make them difficult to import, including data spread over sheets, inconsistent column structures, and blank rows/columns. We will use the **readxl** package and `read_excel()` function to import these files. 

Excel files cannot be imported directly from GitHub, so you'll need to download the file from the test datasets: https://github.com/mcas-surg/Tutorials/blob/main/Datasets/excel_import_example.xlsx

Our file has three sheets, the first is the simplest case. 

```{r}
library(readxl)

simple_excel <- read_excel("Datasets/excel_import_example.xlsx",
                           sheet = "Sheet1")

head(simple_excel)
```

Note we can specify the exact name of the sheet. If we don't it will default to the first sheet in the Excel file. In the second sheet of our example, the data are offset and we need to define an explicit range of the cells. 

```{r}
offset_excel <- read_excel("Datasets/excel_import_example.xlsx",
                           sheet = "Sheet2",
                           range = "C5:F10")

head(offset_excel)
```

# Importing SAS files

The **haven** package makes importing .sas7bdat files very straightforward. The `read_sas()` function works in much the same way as `read_csv()`. We can import an example taken from a dataset on primary biliary cirrhosis. The source is
'https://vincentarelbundock.github.io/Rdatasets/datasets.html' under the dataset name 'Mayo Clinic Primary Biliary Cirrhosis Data'.

```{r}
library(haven)

urlRemote  <- "https://raw.githubusercontent.com/"
pathGithub <- "mcas-surg/Tutorials/main/Datasets/"
fileName   <- "pbc.sas7bdat"

pbc <- read_sas(paste0(urlRemote, pathGithub, fileName))

head(pbc)
```

# Common cleaning issues

Now that we've covered importing the most common file types, we can review issues that come up with importing. Let's use the third sheet of our Excel file, which has the following form. 

```{r, echo=FALSE, out.width="100%"}
knitr::include_graphics("C:/Users/matth/Documents/R/R code and education/Tutorials/Photos/excel_example.png")
```

Here are issues we can identify

1. Excel file with the data on the third sheet
2. Need to set the correct range of the data
3. The non-estimable formula giving the "#VALUE!" error
4. Missing data specified by the text "Missing" 
5. Non-compatible variable names
6. Multiple text strings indicating patient died

The first two issues can be solved with the previous options we learned during importation.

```{r}
complex_excel <- read_excel("Datasets/excel_import_example.xlsx",
                           sheet = "Sheet3",
                           range = "C8:G18")

complex_excel
```

Note the `NA` value in the *Age/10* column. R already recognized the formula error in Excel and made the value missing. We don't need to do anything else, so the first three issues are solved. 

Missing data has been specified by the text "Missing". This can be fixed during import by setting the `na = ` option. Let's update our import program. 

```{r}
complex_excel <- read_excel("Datasets/excel_import_example.xlsx",
                           sheet = "Sheet3",
                           range = "C8:G18",
                           na = "Missing")

complex_excel
```

If you look back, you will notice this also fixed *Age (years)* being imported as a character variable due to the "Missing" string. It is now correctly a numeric variable. 

Unfortunately, the variable names are not R-compatible. We can see they are wrapped in single quotes. When we have non-compatible variable names we can still refer to them by using this strategy. For example, selecting the *Patient ID* variable, which contains a space. 

```{r}
complex_excel %>% 
  select(`Patient ID`)
```

Working with non-standard variable names is obviously more work and will cause errors. Let's use the `colnames()` strategy and change them. 

```{r}
colnames(complex_excel) <- c("patient_id",
                             "age",
                             "surgery",
                             "outcome",
                             "age_divided")

complex_excel
```

The final issue is the *outcome* variable. We have values for both "Die" and "Died". We need to create a common value. We can accomplish this and convert the variable to a factor in the same step. The `factor()` function has two important arguments - `levels = ` indicates the desired order the categories, and `labels = ` lets you change the values themselves, including combining categories. 

Let's convert *outcome* to a factor. 

```{r}
complex_excel <- complex_excel %>% 
  mutate(outcome = factor(outcome, 
                          levels = c("Survived", "Died", "Die"),
                          labels = c("Survived", "Died", "Died")))

complex_excel
```

We can show summary statistics to look for final problems. 

```{r}
summary(complex_excel)
```

Since we never changed *surgery* to a factor it cannot be summarized in this method. We will also change it to a factor. 

```{r}
complex_excel <- complex_excel %>% 
  mutate(surgery = factor(surgery))

summary(complex_excel)
```

Now that our dataset is cleaned, a quick check can be done for missing data. The function `is.na()` will provide `TRUE` or `FALSE` for each value depending on its missing status. For example, on a single variable. 

```{r}
is.na(complex_excel$surgery)
```

We see one `TRUE`. This is hard to read, so we can ask R to sum the column. `TRUE` is treated as 1 and `FALSE` as 0 by default. 

```{r}
sum(is.na(complex_excel$surgery))
```

As expected, 1 missing. We can extend this to all the columns using `colSums()` and passing the entire dataset to `is.na()`. 

```{r}
colSums(is.na(complex_excel))
```

To summarize, we have learned how to import .csv files, general text delimited files, Excel files, and SAS files. We have also gone over a short example of data cleaning. 
